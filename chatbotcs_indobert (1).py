# -*- coding: utf-8 -*-
"""chatbotCS_indoBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wvC8N3hxcbjCHmmTPf8f0YD8p7J2P1FK
"""

!pip install transformers torch pandas scikit-learn

from google.colab import files
import pandas as pd
from transformers import AutoTokenizer, AutoModel
import torch

# Upload file
uploaded = files.upload()  # Pilih faq_penerimaan.csv

df = pd.read_csv("faq_penerimaan.csv")
print(df.head())

# âœ… BENAR â€” Model ringan dan tersedia
model_name = "cahya/distilbert-base-indonesian"

# Load tokenizer dan model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# Pindah ke GPU jika tersedia
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

print("âœ… Model berhasil dimuat!")

"""# Load model dan tokenizer
model_name = "cahya/distilbert-base-indonesian"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)
"""

def encode_text(text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
    embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token
    return embeddings.cpu().numpy()

# Encode semua pertanyaan FAQ
faq_questions = df['pertanyaan'].tolist()
faq_embeddings = encode_text(faq_questions)

print("âœ… Embedding FAQ selesai.")
print("Shape:", faq_embeddings.shape)  # Contoh: (10, 768)

#kalimat tambahan jawaban pembuka dan penutup
import random

# Tambahkan daftar kalimat friendly
friendly_openings = [
    "Hai kak, ðŸ˜Š",
    "Halo, terima kasih sudah bertanya!",
    "Hai, aku bantu jawab ya ðŸ‘‡",
    "Halo kak! ðŸ™Œ"
]

friendly_endings = [
    "Semoga membantu ya!",
    "Kalau masih bingung, boleh tanya lagi ðŸ˜Š",
    "Semoga infonya jelas ya kak!",
    "Kalau ada pertanyaan lain, feel free buat tanya!"
]

def make_friendly(jawaban):
    opening = random.choice(friendly_openings)
    ending = random.choice(friendly_endings)
    return f"{opening}\n\n{jawaban}\n\n{ending}"

from sklearn.metrics.pairwise import cosine_similarity

def cari_jawaban(pertanyaan_user):
    user_embedding = encode_text([pertanyaan_user])
    similarities = cosine_similarity(user_embedding, faq_embeddings)
    idx = similarities.argmax()
    max_sim = similarities[0, idx]

    if max_sim < 0.6:
        return "Maaf, saya tidak mengerti pertanyaan Anda. Silakan hubungi admin di 0812-3456-7890."

    jawaban = df.iloc[idx]['jawaban']

    # return f"ðŸ’¬: {jawaban}" jawaban yg blm diimprove
    return make_friendly(jawaban) #jawaban yg sudah diimporve ada pembuka dan penutup

"""pertanyaan_user = "Di mana lokasi sekolah?"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)
"""

pertanyaan_user = "gimana cara daftar kak?"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)

pertanyaan_user = "info beasiswa dong kak saya mau daftar dengan jalur beasiswa"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)

pertanyaan_user = "saya mau nomor kepala sekolahnya"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)

pertanyaan_user = "siapa nama mu?"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)

pertanyaan_user = "gimana alur seleksinya?"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)

pertanyaan_user = "alamat sekolah"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)

pertanyaan_user = "infonya gak jelas kak"
jawaban = cari_jawaban(pertanyaan_user)
print(jawaban)